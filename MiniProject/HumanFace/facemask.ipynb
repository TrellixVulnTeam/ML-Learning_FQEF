{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler,ReduceLROnPlateau\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tensorflow.keras.applications import MobileNetV2,EfficientNetB0\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8982 files belonging to 3 classes.\n",
      "Using 7186 files for training.\n",
      "Found 8982 files belonging to 3 classes.\n",
      "Using 1796 files for validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-28 13:54:01.873049: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-01-28 13:54:01.873211: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-28 13:54:01.874017: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory('/home/lacie/Data/MaskFace/Dataset', validation_split=0.2, subset=\"training\", shuffle=True, seed = 2021, labels='inferred', batch_size=32, image_size=(224,224))\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory('/home/lacie/Data/MaskFace/Dataset', validation_split=0.2, subset=\"validation\", shuffle=True, seed = 2021, labels='inferred', batch_size=32, image_size=(224,224))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "['mask_weared_incorrect', 'with_mask', 'without_mask']"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.class_names"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class_name = ['Incorrect','With_Mask','Without_Mask']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-28 13:54:47.182945: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-01-28 13:54:47.202526: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3199980000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 224, 224, 3)\n",
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.shape)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "(<tf.Tensor: shape=(224, 224, 3), dtype=float32, numpy=\n array([[[  5.        ,   3.        ,   4.        ],\n         [ 18.214289  ,  16.214289  ,  17.214289  ],\n         [ 39.357143  ,  37.357143  ,  38.357143  ],\n         ...,\n         [125.14287   , 125.14287   , 125.14287   ],\n         [126.28572   , 126.28572   , 126.28572   ],\n         [127.        , 127.        , 127.        ]],\n \n        [[  3.5714283 ,   1.9285712 ,   2.5714283 ],\n         [ 13.469389  ,  11.826532  ,  12.469389  ],\n         [ 29.306122  ,  27.663265  ,  28.306122  ],\n         ...,\n         [126.57144   , 126.57144   , 126.57144   ],\n         [127.714294  , 127.714294  , 127.714294  ],\n         [128.42857   , 128.42857   , 128.42857   ]],\n \n        [[  1.2857141 ,   0.21428561,   0.28571415],\n         [  5.877551  ,   4.806123  ,   4.877551  ],\n         [ 13.224489  ,  12.153061  ,  12.224489  ],\n         ...,\n         [128.85715   , 128.85715   , 128.85715   ],\n         [130.        , 130.        , 130.        ],\n         [130.71428   , 130.71428   , 130.71428   ]],\n \n        ...,\n \n        [[  9.        ,   5.928566  ,   6.928566  ],\n         [  9.714286  ,   5.928566  ,   7.285709  ],\n         [ 10.857143  ,   5.928566  ,   7.8571377 ],\n         ...,\n         [  4.0663314 ,   4.8622346 ,   6.0663314 ],\n         [  4.0255117 ,   4.331628  ,   5.4540854 ],\n         [  4.        ,   4.        ,   5.071434  ]],\n \n        [[  9.        ,   5.3571396 ,   6.3571396 ],\n         [  9.714286  ,   5.3571396 ,   6.7142825 ],\n         [ 10.857143  ,   5.3571396 ,   7.2857113 ],\n         ...,\n         [  4.596938  ,   4.331628  ,   7.1683645 ],\n         [  4.229591  ,   4.1275487 ,   6.229591  ],\n         [  4.        ,   4.        ,   5.6428604 ]],\n \n        [[  9.        ,   5.        ,   6.        ],\n         [  9.714286  ,   5.        ,   6.357143  ],\n         [ 10.857143  ,   5.        ,   6.9285717 ],\n         ...,\n         [  4.928566  ,   4.        ,   7.857132  ],\n         [  4.3571396 ,   4.        ,   6.714279  ],\n         [  4.        ,   4.        ,   6.        ]]], dtype=float32)>,\n <tf.Tensor: shape=(), dtype=int32, numpy=2>)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_batch, labels_batch = next(iter(train_ds))\n",
    "image_batch[0], labels_batch[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9412608/9406464 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(layers.experimental.preprocessing.Rescaling(1./255, input_shape=(224,224,3)))\n",
    "model.add(MobileNetV2(weights=\"imagenet\", include_top=False))\n",
    "\n",
    "model.add(layers.AveragePooling2D(pool_size=(7, 7)))\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(3, activation='softmax'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rescaling (Rescaling)        (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "mobilenetv2_1.00_224 (Functi (None, None, None, 1280)  2257984   \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 1, 1, 1280)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               163968    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 2,426,179\n",
      "Trainable params: 2,392,067\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "225/225 [==============================] - 1148s 5s/step - loss: 0.2729 - accuracy: 0.9048 - val_loss: 11.1193 - val_accuracy: 0.4716\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.47160, saving model to MaskDetection.h5\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 1151s 5s/step - loss: 0.1027 - accuracy: 0.9693 - val_loss: 6.0102 - val_accuracy: 0.7060\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.47160 to 0.70601, saving model to MaskDetection.h5\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 1150s 5s/step - loss: 0.0653 - accuracy: 0.9835 - val_loss: 11.5268 - val_accuracy: 0.4861\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.70601\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 1162s 5s/step - loss: 0.0740 - accuracy: 0.9787 - val_loss: 4.0940 - val_accuracy: 0.6670\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.70601\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 1163s 5s/step - loss: 0.0361 - accuracy: 0.9887 - val_loss: 5.4783 - val_accuracy: 0.5768\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.70601\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 1150s 5s/step - loss: 0.0391 - accuracy: 0.9891 - val_loss: 4.3337 - val_accuracy: 0.7361\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.70601 to 0.73608, saving model to MaskDetection.h5\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 1139s 5s/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.9744 - val_accuracy: 0.8853\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.73608 to 0.88530, saving model to MaskDetection.h5\n",
      "Epoch 8/10\n",
      "225/225 [==============================] - 1099s 5s/step - loss: 0.0202 - accuracy: 0.9934 - val_loss: 0.8581 - val_accuracy: 0.9404\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.88530 to 0.94042, saving model to MaskDetection.h5\n",
      "Epoch 9/10\n",
      "225/225 [==============================] - 1123s 5s/step - loss: 0.0240 - accuracy: 0.9933 - val_loss: 3.2144 - val_accuracy: 0.7422\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.94042\n",
      "Epoch 10/10\n",
      "225/225 [==============================] - 1233s 5s/step - loss: 0.0358 - accuracy: 0.9884 - val_loss: 1.1208 - val_accuracy: 0.9070\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.94042\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7fa9b00db610>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_best = tf.keras.callbacks.ModelCheckpoint(\"MaskDetection.h5\",monitor='val_accuracy',save_best_only=True, verbose=1)\n",
    "\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=10, callbacks=[save_best])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 34s 600ms/step - loss: 1.1208 - accuracy: 0.9070\n"
     ]
    },
    {
     "data": {
      "text/plain": "[1.12076997756958, 0.9070155620574951]"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_ds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]]\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for image_batch, labels_batch in val_ds:\n",
    "    pred = model.predict(image_batch[8].numpy().reshape(-1,224,224,3))\n",
    "    print(pred.round())\n",
    "    print(labels_batch[8])\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}