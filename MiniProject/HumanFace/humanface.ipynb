{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /home/lacie/miniconda3/envs/pytorch/lib/python3.8/site-packages (3.5.0)\r\n",
      "Collecting matplotlib\r\n",
      "  Downloading matplotlib-3.5.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.3 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 11.3 MB 4.0 MB/s eta 0:00:01\r\n",
      "\u001B[?25hRequirement already satisfied: numpy in /home/lacie/miniconda3/envs/pytorch/lib/python3.8/site-packages (1.21.2)\r\n",
      "Collecting numpy\r\n",
      "  Downloading numpy-1.22.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 16.8 MB 208 kB/s eta 0:00:01\r\n",
      "\u001B[?25hRequirement already satisfied: pandas in /home/lacie/miniconda3/envs/pytorch/lib/python3.8/site-packages (1.3.5)\r\n",
      "Collecting pandas\r\n",
      "  Downloading pandas-1.4.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 11.7 MB 3.1 MB/s eta 0:00:01\r\n",
      "\u001B[?25hRequirement already satisfied: scipy in /home/lacie/miniconda3/envs/pytorch/lib/python3.8/site-packages (1.7.3)\r\n",
      "Requirement already satisfied: scikit-learn in /home/lacie/miniconda3/envs/pytorch/lib/python3.8/site-packages (1.0.2)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/lacie/miniconda3/envs/pytorch/lib/python3.8/site-packages (from matplotlib) (8.4.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/lacie/miniconda3/envs/pytorch/lib/python3.8/site-packages (from matplotlib) (4.25.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/lacie/miniconda3/envs/pytorch/lib/python3.8/site-packages (from matplotlib) (1.3.1)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/lacie/miniconda3/envs/pytorch/lib/python3.8/site-packages (from matplotlib) (3.0.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/lacie/miniconda3/envs/pytorch/lib/python3.8/site-packages (from matplotlib) (2.8.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /home/lacie/miniconda3/envs/pytorch/lib/python3.8/site-packages (from matplotlib) (0.11.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /home/lacie/miniconda3/envs/pytorch/lib/python3.8/site-packages (from matplotlib) (21.3)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/lacie/miniconda3/envs/pytorch/lib/python3.8/site-packages (from pandas) (2021.3)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /home/lacie/miniconda3/envs/pytorch/lib/python3.8/site-packages (from scikit-learn) (1.1.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/lacie/miniconda3/envs/pytorch/lib/python3.8/site-packages (from scikit-learn) (3.0.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/lacie/miniconda3/envs/pytorch/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\r\n",
      "Installing collected packages: numpy, pandas, matplotlib\r\n",
      "  Attempting uninstall: numpy\r\n",
      "    Found existing installation: numpy 1.21.2\r\n",
      "    Uninstalling numpy-1.21.2:\r\n",
      "      Successfully uninstalled numpy-1.21.2\r\n",
      "  Attempting uninstall: pandas\r\n",
      "    Found existing installation: pandas 1.3.5\r\n",
      "    Uninstalling pandas-1.3.5:\r\n",
      "      Successfully uninstalled pandas-1.3.5\r\n",
      "  Attempting uninstall: matplotlib\r\n",
      "    Found existing installation: matplotlib 3.5.0\r\n",
      "    Uninstalling matplotlib-3.5.0:\r\n",
      "      Successfully uninstalled matplotlib-3.5.0\r\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "torchvision 0.9.1 requires torch==1.8.1, but you have torch 1.9.0 which is incompatible.\u001B[0m\r\n",
      "Successfully installed matplotlib-3.5.1 numpy-1.22.1 pandas-1.4.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --upgrade matplotlib numpy pandas scipy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\r\n",
      "Solving environment: \\ \r\n",
      "The environment is inconsistent, please check the package plan carefully\r\n",
      "The following packages are causing the inconsistency:\r\n",
      "\r\n",
      "  - defaults/linux-64::imagecodecs==2021.8.26=py38h4cda21f_0\r\n",
      "  - defaults/linux-64::scipy==1.7.3=py38hc147768_0\r\n",
      "  - defaults/linux-64::numexpr==2.8.1=py38h6abb31d_0\r\n",
      "  - conda-forge/noarch::visdom==0.1.8.9=0\r\n",
      "  - pytorch/linux-64::torchaudio==0.9.0=py38\r\n",
      "  - defaults/linux-64::matplotlib==3.5.0=py38h06a4308_0\r\n",
      "  - defaults/linux-64::scikit-learn==1.0.2=py38h51133e4_1\r\n",
      "  - conda-forge/noarch::torchfile==0.1.0=py_0\r\n",
      "  - defaults/linux-64::mkl_random==1.2.2=py38h51133e4_0\r\n",
      "  - conda-forge/linux-64::pytorch==1.9.0=cuda112py38h3d13190_1\r\n",
      "  - conda-forge/linux-64::pytorch-gpu==1.9.0=cuda112py38h0bbbad9_1\r\n",
      "  - defaults/linux-64::scikit-image==0.18.3=py38h51133e4_0\r\n",
      "  - defaults/linux-64::numpy==1.21.2=py38h20f2e39_0\r\n",
      "  - defaults/linux-64::bottleneck==1.3.2=py38heb32a55_1\r\n",
      "  - defaults/noarch::imageio==2.9.0=pyhd3eb1b0_0\r\n",
      "  - defaults/linux-64::pywavelets==1.1.1=py38h7b6447c_2\r\n",
      "  - defaults/noarch::tifffile==2021.7.2=pyhd3eb1b0_2\r\n",
      "  - defaults/linux-64::mkl_fft==1.3.1=py38hd3c417c_0\r\n",
      "failed with initial frozen solve. Retrying with flexible solve.\r\n",
      "Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\r\n",
      "Collecting package metadata (repodata.json): done\r\n",
      "Solving environment: - \r\n",
      "The environment is inconsistent, please check the package plan carefully\r\n",
      "The following packages are causing the inconsistency:\r\n",
      "\r\n",
      "  - defaults/linux-64::imagecodecs==2021.8.26=py38h4cda21f_0\r\n",
      "  - defaults/linux-64::scipy==1.7.3=py38hc147768_0\r\n",
      "  - defaults/linux-64::numexpr==2.8.1=py38h6abb31d_0\r\n",
      "  - conda-forge/noarch::visdom==0.1.8.9=0\r\n",
      "  - pytorch/linux-64::torchaudio==0.9.0=py38\r\n",
      "  - defaults/linux-64::matplotlib==3.5.0=py38h06a4308_0\r\n",
      "  - defaults/linux-64::scikit-learn==1.0.2=py38h51133e4_1\r\n",
      "  - conda-forge/noarch::torchfile==0.1.0=py_0\r\n",
      "  - defaults/linux-64::mkl_random==1.2.2=py38h51133e4_0\r\n",
      "  - conda-forge/linux-64::pytorch==1.9.0=cuda112py38h3d13190_1\r\n",
      "  - conda-forge/linux-64::pytorch-gpu==1.9.0=cuda112py38h0bbbad9_1\r\n",
      "  - defaults/linux-64::scikit-image==0.18.3=py38h51133e4_0\r\n",
      "  - defaults/linux-64::numpy==1.21.2=py38h20f2e39_0\r\n",
      "  - defaults/linux-64::bottleneck==1.3.2=py38heb32a55_1\r\n",
      "  - defaults/noarch::imageio==2.9.0=pyhd3eb1b0_0\r\n",
      "  - defaults/linux-64::pywavelets==1.1.1=py38h7b6447c_2\r\n",
      "  - defaults/noarch::tifffile==2021.7.2=pyhd3eb1b0_2\r\n",
      "  - defaults/linux-64::mkl_fft==1.3.1=py38hd3c417c_0\r\n",
      "done\r\n",
      "\r\n",
      "## Package Plan ##\r\n",
      "\r\n",
      "  environment location: /home/lacie/miniconda3/envs/pytorch\r\n",
      "\r\n",
      "  added / updated specs:\r\n",
      "    - tensorflow\r\n",
      "\r\n",
      "\r\n",
      "The following packages will be downloaded:\r\n",
      "\r\n",
      "    package                    |            build\r\n",
      "    ---------------------------|-----------------\r\n",
      "    absl-py-1.0.0              |     pyhd8ed1ab_0          95 KB  conda-forge\r\n",
      "    aiohttp-3.7.0              |   py38h1e0a361_0         641 KB  conda-forge\r\n",
      "    astor-0.8.1                |     pyh9f0ad1d_0          25 KB  conda-forge\r\n",
      "    astunparse-1.6.3           |     pyhd8ed1ab_0          15 KB  conda-forge\r\n",
      "    async-timeout-3.0.1        |          py_1000          11 KB  conda-forge\r\n",
      "    blinker-1.4                |             py_1          13 KB  conda-forge\r\n",
      "    cachetools-4.2.4           |     pyhd8ed1ab_0          12 KB  conda-forge\r\n",
      "    certifi-2021.10.8          |   py38h578d9bd_1         145 KB  conda-forge\r\n",
      "    chardet-3.0.4              |py38h924ce5b_1008         170 KB  conda-forge\r\n",
      "    click-8.0.3                |   py38h578d9bd_1         146 KB  conda-forge\r\n",
      "    dataclasses-0.8            |     pyhc8e2a94_3          10 KB  conda-forge\r\n",
      "    gast-0.4.0                 |     pyh9f0ad1d_0          12 KB  conda-forge\r\n",
      "    google-auth-2.3.3          |     pyh6c4a22f_0          83 KB  conda-forge\r\n",
      "    google-auth-oauthlib-0.4.6 |     pyhd8ed1ab_0          19 KB  conda-forge\r\n",
      "    google-pasta-0.2.0         |     pyh8c360ce_0          42 KB  conda-forge\r\n",
      "    grpcio-1.38.1              |   py38hdd6454d_0         2.2 MB  conda-forge\r\n",
      "    h5py-2.10.0                |nompi_py38h9915d05_106         1.1 MB  conda-forge\r\n",
      "    hdf5-1.10.6                |nompi_h7c3c948_1111         3.1 MB  conda-forge\r\n",
      "    keras-preprocessing-1.1.2  |     pyhd8ed1ab_0          34 KB  conda-forge\r\n",
      "    markdown-3.3.6             |     pyhd8ed1ab_0          67 KB  conda-forge\r\n",
      "    multidict-5.1.0            |   py38h497a2fe_1          68 KB  conda-forge\r\n",
      "    oauthlib-3.1.1             |     pyhd8ed1ab_0          87 KB  conda-forge\r\n",
      "    opt_einsum-3.3.0           |     pyhd8ed1ab_1          53 KB  conda-forge\r\n",
      "    protobuf-3.16.0            |   py38h709712a_0         344 KB  conda-forge\r\n",
      "    pyasn1-0.4.8               |             py_0          53 KB  conda-forge\r\n",
      "    pyasn1-modules-0.2.7       |             py_0          60 KB  conda-forge\r\n",
      "    pyjwt-2.3.0                |     pyhd8ed1ab_1          18 KB  conda-forge\r\n",
      "    python-flatbuffers-2.0     |     pyhd8ed1ab_0          28 KB  conda-forge\r\n",
      "    pyu2f-0.1.5                |     pyhd8ed1ab_0          31 KB  conda-forge\r\n",
      "    requests-oauthlib-1.3.0    |     pyh9f0ad1d_0          21 KB  conda-forge\r\n",
      "    rsa-4.8                    |     pyhd8ed1ab_0          31 KB  conda-forge\r\n",
      "    tensorboard-2.8.0          |     pyhd8ed1ab_0         5.2 MB  conda-forge\r\n",
      "    tensorboard-data-server-0.6.0|   py38h2b97feb_0         3.2 MB  conda-forge\r\n",
      "    tensorboard-plugin-wit-1.8.1|     pyhd8ed1ab_0         668 KB  conda-forge\r\n",
      "    tensorflow-estimator-2.5.0 |     pyh81a9013_1         289 KB  conda-forge\r\n",
      "    werkzeug-2.0.2             |     pyhd8ed1ab_0         221 KB  conda-forge\r\n",
      "    wrapt-1.12.1               |   py38h497a2fe_3          47 KB  conda-forge\r\n",
      "    yarl-1.6.3                 |   py38h497a2fe_2         143 KB  conda-forge\r\n",
      "    ------------------------------------------------------------\r\n",
      "                                           Total:        18.5 MB\r\n",
      "\r\n",
      "The following NEW packages will be INSTALLED:\r\n",
      "\r\n",
      "  _tflow_select      pkgs/main/linux-64::_tflow_select-2.3.0-mkl\r\n",
      "  absl-py            conda-forge/noarch::absl-py-1.0.0-pyhd8ed1ab_0\r\n",
      "  aiohttp            conda-forge/linux-64::aiohttp-3.7.0-py38h1e0a361_0\r\n",
      "  astor              conda-forge/noarch::astor-0.8.1-pyh9f0ad1d_0\r\n",
      "  astunparse         conda-forge/noarch::astunparse-1.6.3-pyhd8ed1ab_0\r\n",
      "  async-timeout      conda-forge/noarch::async-timeout-3.0.1-py_1000\r\n",
      "  blinker            conda-forge/noarch::blinker-1.4-py_1\r\n",
      "  cachetools         conda-forge/noarch::cachetools-4.2.4-pyhd8ed1ab_0\r\n",
      "  chardet            conda-forge/linux-64::chardet-3.0.4-py38h924ce5b_1008\r\n",
      "  click              conda-forge/linux-64::click-8.0.3-py38h578d9bd_1\r\n",
      "  dataclasses        conda-forge/noarch::dataclasses-0.8-pyhc8e2a94_3\r\n",
      "  gast               conda-forge/noarch::gast-0.4.0-pyh9f0ad1d_0\r\n",
      "  google-auth        conda-forge/noarch::google-auth-2.3.3-pyh6c4a22f_0\r\n",
      "  google-auth-oauth~ conda-forge/noarch::google-auth-oauthlib-0.4.6-pyhd8ed1ab_0\r\n",
      "  google-pasta       conda-forge/noarch::google-pasta-0.2.0-pyh8c360ce_0\r\n",
      "  grpcio             conda-forge/linux-64::grpcio-1.38.1-py38hdd6454d_0\r\n",
      "  h5py               conda-forge/linux-64::h5py-2.10.0-nompi_py38h9915d05_106\r\n",
      "  hdf5               conda-forge/linux-64::hdf5-1.10.6-nompi_h7c3c948_1111\r\n",
      "  keras-preprocessi~ conda-forge/noarch::keras-preprocessing-1.1.2-pyhd8ed1ab_0\r\n",
      "  markdown           conda-forge/noarch::markdown-3.3.6-pyhd8ed1ab_0\r\n",
      "  matplotlib-base    pkgs/main/linux-64::matplotlib-base-3.5.0-py38h3ed280b_0\r\n",
      "  multidict          conda-forge/linux-64::multidict-5.1.0-py38h497a2fe_1\r\n",
      "  numpy-base         pkgs/main/linux-64::numpy-base-1.21.2-py38h79a1101_0\r\n",
      "  oauthlib           conda-forge/noarch::oauthlib-3.1.1-pyhd8ed1ab_0\r\n",
      "  opt_einsum         conda-forge/noarch::opt_einsum-3.3.0-pyhd8ed1ab_1\r\n",
      "  protobuf           conda-forge/linux-64::protobuf-3.16.0-py38h709712a_0\r\n",
      "  pyasn1             conda-forge/noarch::pyasn1-0.4.8-py_0\r\n",
      "  pyasn1-modules     conda-forge/noarch::pyasn1-modules-0.2.7-py_0\r\n",
      "  pyjwt              conda-forge/noarch::pyjwt-2.3.0-pyhd8ed1ab_1\r\n",
      "  python-flatbuffers conda-forge/noarch::python-flatbuffers-2.0-pyhd8ed1ab_0\r\n",
      "  pyu2f              conda-forge/noarch::pyu2f-0.1.5-pyhd8ed1ab_0\r\n",
      "  requests-oauthlib  conda-forge/noarch::requests-oauthlib-1.3.0-pyh9f0ad1d_0\r\n",
      "  rsa                conda-forge/noarch::rsa-4.8-pyhd8ed1ab_0\r\n",
      "  tensorboard        conda-forge/noarch::tensorboard-2.8.0-pyhd8ed1ab_0\r\n",
      "  tensorboard-data-~ conda-forge/linux-64::tensorboard-data-server-0.6.0-py38h2b97feb_0\r\n",
      "  tensorboard-plugi~ conda-forge/noarch::tensorboard-plugin-wit-1.8.1-pyhd8ed1ab_0\r\n",
      "  tensorflow         pkgs/main/linux-64::tensorflow-2.4.1-mkl_py38hb2083e0_0\r\n",
      "  tensorflow-base    pkgs/main/linux-64::tensorflow-base-2.4.1-mkl_py38h43e0292_0\r\n",
      "  tensorflow-estima~ conda-forge/noarch::tensorflow-estimator-2.5.0-pyh81a9013_1\r\n",
      "  werkzeug           conda-forge/noarch::werkzeug-2.0.2-pyhd8ed1ab_0\r\n",
      "  wrapt              conda-forge/linux-64::wrapt-1.12.1-py38h497a2fe_3\r\n",
      "  yarl               conda-forge/linux-64::yarl-1.6.3-py38h497a2fe_2\r\n",
      "\r\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\r\n",
      "\r\n",
      "  ca-certificates    pkgs/main::ca-certificates-2021.10.26~ --> conda-forge::ca-certificates-2021.10.8-ha878542_0\r\n",
      "  certifi            pkgs/main::certifi-2021.10.8-py38h06a~ --> conda-forge::certifi-2021.10.8-py38h578d9bd_1\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "Downloading and Extracting Packages\r\n",
      "markdown-3.3.6       | 67 KB     | ##################################### | 100% \r\n",
      "pyasn1-modules-0.2.7 | 60 KB     | ##################################### | 100% \r\n",
      "pyjwt-2.3.0          | 18 KB     | ##################################### | 100% \r\n",
      "keras-preprocessing- | 34 KB     | ##################################### | 100% \r\n",
      "blinker-1.4          | 13 KB     | ##################################### | 100% \r\n",
      "python-flatbuffers-2 | 28 KB     | ##################################### | 100% \r\n",
      "rsa-4.8              | 31 KB     | ##################################### | 100% \r\n",
      "google-auth-2.3.3    | 83 KB     | ##################################### | 100% \r\n",
      "pyu2f-0.1.5          | 31 KB     | ##################################### | 100% \r\n",
      "tensorflow-estimator | 289 KB    | ##################################### | 100% \r\n",
      "dataclasses-0.8      | 10 KB     | ##################################### | 100% \r\n",
      "hdf5-1.10.6          | 3.1 MB    | ##################################### | 100% \r\n",
      "google-auth-oauthlib | 19 KB     | ##################################### | 100% \r\n",
      "gast-0.4.0           | 12 KB     | ##################################### | 100% \r\n",
      "protobuf-3.16.0      | 344 KB    | ##################################### | 100% \r\n",
      "chardet-3.0.4        | 170 KB    | ##################################### | 100% \r\n",
      "async-timeout-3.0.1  | 11 KB     | ##################################### | 100% \r\n",
      "tensorboard-2.8.0    | 5.2 MB    | ##################################### | 100% \r\n",
      "h5py-2.10.0          | 1.1 MB    | ##################################### | 100% \r\n",
      "multidict-5.1.0      | 68 KB     | ##################################### | 100% \r\n",
      "cachetools-4.2.4     | 12 KB     | ##################################### | 100% \r\n",
      "click-8.0.3          | 146 KB    | ##################################### | 100% \r\n",
      "absl-py-1.0.0        | 95 KB     | ##################################### | 100% \r\n",
      "werkzeug-2.0.2       | 221 KB    | ##################################### | 100% \r\n",
      "wrapt-1.12.1         | 47 KB     | ##################################### | 100% \r\n",
      "astor-0.8.1          | 25 KB     | ##################################### | 100% \r\n",
      "yarl-1.6.3           | 143 KB    | ##################################### | 100% \r\n",
      "grpcio-1.38.1        | 2.2 MB    | ##################################### | 100% \r\n",
      "opt_einsum-3.3.0     | 53 KB     | ##################################### | 100% \r\n",
      "astunparse-1.6.3     | 15 KB     | ##################################### | 100% \r\n",
      "pyasn1-0.4.8         | 53 KB     | ##################################### | 100% \r\n",
      "oauthlib-3.1.1       | 87 KB     | ##################################### | 100% \r\n",
      "tensorboard-plugin-w | 668 KB    | ##################################### | 100% \r\n",
      "certifi-2021.10.8    | 145 KB    | ##################################### | 100% \r\n",
      "aiohttp-3.7.0        | 641 KB    | ##################################### | 100% \r\n",
      "requests-oauthlib-1. | 21 KB     | ##################################### | 100% \r\n",
      "tensorboard-data-ser | 3.2 MB    | ##################################### | 100% \r\n",
      "google-pasta-0.2.0   | 42 KB     | ##################################### | 100% \r\n",
      "Preparing transaction: done\r\n",
      "Verifying transaction: done\r\n",
      "Executing transaction: done\r\n"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge tensorflow -y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\r\n",
      "  Using cached opencv_python-4.5.5.62-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.4 MB)\r\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/lacie/miniconda3/envs/pytorch/lib/python3.8/site-packages (from opencv-python) (1.22.1)\r\n",
      "Installing collected packages: opencv-python\r\n",
      "Successfully installed opencv-python-4.5.5.62\r\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2,os\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "n_classes = 2\n",
    "# path_incorrect = '/home/lacie/Data/MaskFace/Dataset/mask_weared_incorrect'\n",
    "path_with_mask = '/home/lacie/Data/MaskFace/Dataset/with_mask'\n",
    "path_without_mask = '/home/lacie/Data/MaskFace/Dataset/without_mask'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def read_data(path, label):\n",
    "    images = []\n",
    "    labels = []\n",
    "    dirs = os.listdir(path)\n",
    "    for files in dirs:\n",
    "        file_name = path + \"/\" + files\n",
    "        image = cv2.imread(file_name, 0)\n",
    "        #image = np.reshape(image, 40*100)\n",
    "        images.append(image)\n",
    "        labels.append(label)\n",
    "    return images, labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "# images_incorrect, labels_incorrect = read_data(path_incorrect, 0)\n",
    "images_with_mask, labels_with_mask = read_data(path_with_mask, 0)\n",
    "images_without_mask, labels_without_mask = read_data(path_without_mask, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "images = images_with_mask + images_without_mask\n",
    "labels = labels_without_mask + labels_with_mask"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "[1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n ...]"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "x_train, x_test,y_train,y_test = train_test_split(images, labels,test_size=0.1, random_state=41, stratify=labels)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "x_train=np.asarray(x_train)\n",
    "y_train=np.asarray(y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "def conv_net(x):\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1]) # input layer, image size input có kích thước 28x28\n",
    "    conv1 = tf.layers.conv2d(x, 32, 5, activation=tf.nn.relu,padding=\"SAME\") # convolutional layer 1\n",
    "    conv1 = tf.layers.max_pooling2d(conv1, 2, 2,padding=\"SAME\") # pooling layer 1\n",
    "    conv2 = tf.layers.conv2d(conv1, 64, 5, activation=tf.nn.relu,padding=\"SAME\") # convolutional layer 2\n",
    "    conv2 = tf.layers.max_pooling2d(conv2, 2, 2,padding=\"SAME\") # pooling layer 2\n",
    "\n",
    "    fc1 = tf.contrib.layers.flatten(conv2)\n",
    "    fc1 = tf.layers.dense(fc1, 512,activation=tf.nn.relu)\n",
    "    out = tf.layers.dense(fc1, n_classes,name=\"output\")\n",
    "\n",
    "    return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "batch_size = 20\n",
    "display_step = 10\n",
    "num_steps=200\n",
    "# Network Parameters\n",
    "n_input = 4000\n",
    "num_classes=2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'layers'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_27675/2042320184.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcompat\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mv1\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mplaceholder\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat32\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_input\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"x\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcompat\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mv1\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mplaceholder\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mint32\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"y\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mpred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconv_net\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mxentropy\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msparse_softmax_cross_entropy_with_logits\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlogits\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mpred\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_27675/697387346.py\u001B[0m in \u001B[0;36mconv_net\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mconv_net\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m     \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshape\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m28\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m28\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;31m# input layer, image size input có kích thước 28x28\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m     \u001B[0mconv1\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayers\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconv2d\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m32\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m5\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mactivation\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrelu\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mpadding\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"SAME\"\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;31m# convolutional layer 1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m     \u001B[0mconv1\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayers\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmax_pooling2d\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconv1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mpadding\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"SAME\"\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;31m# pooling layer 1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0mconv2\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayers\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconv2d\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconv1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m64\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m5\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mactivation\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrelu\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mpadding\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"SAME\"\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;31m# convolutional layer 2\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'tensorflow' has no attribute 'layers'"
     ]
    }
   ],
   "source": [
    "x = tf.compat.v1.placeholder(tf.float32, [None, n_input],name=\"x\")\n",
    "y = tf.compat.v1.placeholder(tf.int32, [None],name=\"y\")\n",
    "pred = conv_net(x)\n",
    "\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=pred, labels=y)\n",
    "cost = tf.reduce_mean(xentropy)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "training_op=optimizer.minimize(cost)\n",
    "\n",
    "correct = tf.nn.in_top_k(pred, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "init = tf.global_variables_initializer()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_27675/2264895675.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mmatplotlib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpyplot\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mget_ipython\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun_line_magic\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'matplotlib'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'inline'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m \u001B[0;32mimport\u001B[0m \u001B[0mseaborn\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0msns\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      6\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mkeras\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler,ReduceLROnPlateau\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tensorflow.keras.applications import MobileNetV2,EfficientNetB0\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}